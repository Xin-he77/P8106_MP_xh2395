---
title: "P8106 Midterm Report"
author: "Xin  He"
date: "4/5/2020"
output: pdf_document

\fontsize: 11
    - \textwidth 6.75in
    - \textheight 8.5in
    - \oddsidemargin -.25in
    - \evensidemargin -.25in
    - \topmargin -0.5in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    fig.align = 'center',
    message = F,
    warning = F,
    echo = T
 )

library(tidyverse)
library(caret)
library(pls)
library(patchwork)
library(splines)
library(gam)
library(mgcv)
library(boot)
library(ggplot2)
library(pdp)
library(earth)

theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5) 
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1) 
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)
```

# Introduction

Once viewed as a luxury good, nowadays red wine is increasingly enjoyed by a wider range of consumers, including our teammates. We noticed that the price and quality of differnet brands of red wine differ. We are interested in investigating what chemical elements of red wine are related to its quality. 

We focused on a dataset named "Red Wine Quality", which is related to the Portuguese "Vinho Verde" wine. It includes information about different chemical elements of red wine and its quality score. The dataset is composed of 12 variables and 1599 observations. There is no missing data in our dataset. Among the 12 variables, we chose "quality" as our outome variable and the other 11 variables as predict variables. The outcome variable "quality" is based on sensory data and scored between 0 and 10. The 11 predict variables are fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.

We are trying to build different models to answer the question that what is the relationship between 11 chemical elements of red wine and the quality score of red wine. We seperated the full dataset into a train dataset and a test dataset. The train dataset includes 1200 observations. The test dataset includes 399 observations. 

```{r, include = FALSE}
## Set random seed
set.seed(2020)
## Import the data
wine_df = read_csv("./data/winequality_red.csv")
## Set train data and test data
trRows = createDataPartition(wine_df$quality, p = .75, list = F)
train_df = wine_df[trRows,]
test_df = wine_df[-trRows,]
## Define X, Y and control
# full data
full_X = model.matrix(quality ~ .,wine_df)[,-1]
full_Y = wine_df$quality
# train data
train_X = model.matrix(quality ~ .,train_df)[,-1]
train_Y = train_df$quality
# test data
test_X = model.matrix(quality ~ .,test_df)[,-1]
test_Y = test_df$quality
# Control
train_control = trainControl(method = "cv",number = 10)
```

# Exploratory analysis/visualization

**Response vs Predictors**

```{r,echo = FALSE,fig.height=3}
featurePlot(full_X, full_Y, plot = "scatter", labels = c("","Y"), type = c("p"), layout = c(6, 2))
```

The above figure shows the scatter plots between quality score of red wine and each 11 predictors. The range of red wine quality score is from 3 to 8. Most of the quality scores lie between 5 and 7. Since the total range of quality score is from 0 to 10, there is no red wine with extermely low quality or extremely high quality. We also found that the relationships between each predictor and quality score are differnt. For predictor sulphates, total sulfur dioxide, residual sugar, chlorides, free sulfur dioxide and volatile acidity, the data points are concentrated at the left part of the plot. For predictor alcohol, density, pH, fixed acidity and citric acid, the data points are concentrated at the middle part of the plot.

# Models

```{r,include = FALSE}
## Linear model
lm_fit = train(
    x = train_X,
    y = train_Y, 
    method = 'lm',
    trControl = train_control,
    metric = 'RMSE'
)
## Ridge regression model
ridge_fit = train(
    x = train_X,
    y = train_Y, 
    method = 'glmnet',
    tuneGrid = expand.grid(alpha = 0,lambda = exp(seq(-8, 10, length = 100))),
    trControl = train_control,
    metric = 'RMSE'
)
## Lasso regression model
lasso_fit = train(
    x = train_X,
    y = train_Y, 
    method = 'glmnet',
    tuneGrid = expand.grid(alpha = 1,lambda = exp(seq(-8, 10, length = 100))),
    trControl = train_control
)
## Principle component regression model
pcr_fit = train(
    x = train_X,
    y = train_Y, 
    method = 'pcr',
    tuneLength = length(train_df) - 1,
    trControl = train_control,
    scale = TRUE
)
## Generalized Additive Model
wine_df1 = wine_df %>% 
  rename(fixed_acidity = `fixed acidity`,
         volatile_acidity = `volatile acidity`,
         citric_acid = `citric acid`,
         residual_sugar =`residual sugar`,
         free_sulfur_dioxide = `free sulfur dioxide`,
         total_sulfur_dioxide =`total sulfur dioxide`)

full1_X = model.matrix(quality ~ .,wine_df1)[,-1]
full1_Y = wine_df1$quality

gam_fit = train(full1_X, full1_Y,
                 method = "gam",
                 tuneGrid = data.frame(method = "GCV.Cp", 
                                       select = c(TRUE,FALSE)), 
                 trControl = train_control)
## Multivariate Adaptive Regression Splines Model
mars_grid = expand.grid(degree = 1:2,
                         nprune = 2:10)

mars_fit = train(train_X, train_Y, 
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = train_control)
```

```{r,echo = FALSE,fig.height=3}
## Compare different models
resamp = resamples(list(lm = lm_fit,
                        ridge = ridge_fit,
                        lasso = lasso_fit,
                        pcr = pcr_fit,
                        gam = gam_fit,
                        mars = mars_fit))
bwplot(resamp, metric = "RMSE")
```

We built Linear Regression Model, Ridge Regression Model, Lasso Regression Model, Principle Component Regression Model, Generalized Additive Model and Multivariate Adaptive Regression Splines Model seperately to fit the data. We used "caret" package to make cross-validation and used resamp() to compare the six different models. From the above figure, we can see that the Lasso Regression Model has the smallest median RMSE. 

| Method | MAE | RMSE | R-squared |
|:----------------:|:--------:|:--------:|:--------:|
|Linear Regression|0.5017788|0.6532942|0.3589953|
| Ridge           |0.5029094|0.6531035|0.3595150|
| Lasso           |0.5033725|0.6515125|0.3632421|
| PCR             |0.5018887|0.6526109|0.3632000|
| GAM             |0.4984269|0.6430926|0.3681262|
| **MARS**            |**0.4944765**|**0.6469938**|**0.3690868**|

From the above table, we found that MARS model has relative small MAE and RMSE, and relative large R-squared. We decided to see more details about this model.

**Summary of MARS**

```{r,echo = FALSE,fig.height=3}
ggplot(mars_fit)
```

```{r,echo = FALSE}
summary(mars_fit)
```

Our MARS model is with degree=2 and nprune=4. GCV=0.4161648, RSS=492.3481, GRSq=0.3728199, RSq=0.3806417. Except intercept, the three coefficients are h(12.1-alcohol), h(0.84-volatile acidity) * h(126-total sulfur dioxide) and h(65-total sulfur dioxide) * h(0.76-sulphates). Therefore, alcohol, volatile acidity, total sulfur dioxide and sulphates play important roles in predicting red wine quality. 

**Limitations**
The outcome of the dataset, quality score, is actually a categorical variable. However, we just treated it as a continuous variable in our analysis. It might be more appropriate to use LDA or other method of classification to analysis it.

# Conclusions

Each of the 11 predictors has a different relationship with the outcome, red wine quality. Comparing to Linear Regression Model, Ridge Regression Model, Lasso Regression Model, Principle Component Regression Model and Generalized Additive Model, Multivariate Adaptive Regression Splines Model is relatively more appropriate to predict red wine quality. In MARS model, alcohol, volatile acidity, total sulfur dioxide and sulphates play important roles in predicting red wine quality. 




